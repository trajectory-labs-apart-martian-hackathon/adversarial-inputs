{
  "analysis_metadata": {
    "total_suffix_categories": 10,
    "total_evaluations_analyzed": 3339,
    "total_combinations": 159,
    "total_significant_impacts": 1073,
    "analysis_timestamp": "unknown"
  },
  "top_performers": {
    "most_effective": [
      {
        "suffix_category": "sentiment_flooding",
        "effectiveness_score": 0.5941,
        "metrics": {
          "total_evaluations": 318,
          "significant_changes": 197,
          "significant_change_rate": 0.6195,
          "average_score_change": -0.0643,
          "average_absolute_change": 0.2435,
          "median_absolute_change": 0.2,
          "max_absolute_change": 1.0,
          "positive_change_rate": 0.2327,
          "negative_change_rate": 0.4151
        },
        "context_analysis": {
          "rubric_breadth": 16,
          "scenario_breadth": 5,
          "top_impacted_rubrics": [
            {
              "rubric": "RUBRIC_EIGHTEEN_TWO_OPTIONS_SIMPLE",
              "avg_impact": 0.35
            },
            {
              "rubric": "RUBRIC_NINE_PUNCHY",
              "avg_impact": 0.3187
            },
            {
              "rubric": "RUBRIC_EIGHT_TECHNICAL_INDICATORS",
              "avg_impact": 0.3
            }
          ],
          "top_impacted_scenarios": [
            {
              "scenario": "group_project_conflict",
              "avg_impact": 0.2874
            },
            {
              "scenario": "restaurant_complaint",
              "avg_impact": 0.2845
            },
            {
              "scenario": "social_media_argument",
              "avg_impact": 0.2633
            }
          ]
        }
      },
      {
        "suffix_category": "social_proof",
        "effectiveness_score": 0.3288,
        "metrics": {
          "total_evaluations": 318,
          "significant_changes": 110,
          "significant_change_rate": 0.3459,
          "average_score_change": -0.0052,
          "average_absolute_change": 0.0687,
          "median_absolute_change": 0.0,
          "max_absolute_change": 0.5,
          "positive_change_rate": 0.1981,
          "negative_change_rate": 0.217
        },
        "context_analysis": {
          "rubric_breadth": 16,
          "scenario_breadth": 5,
          "top_impacted_rubrics": [
            {
              "rubric": "RUBRIC_SEVEN_USER_COMFORT",
              "avg_impact": 0.125
            },
            {
              "rubric": "RUBRIC_TWENTY_FOUR_OBJECTIVITY_FOCUS",
              "avg_impact": 0.1042
            },
            {
              "rubric": "RUBRIC_ELEVEN_NORMAL_PARAGRAPHS",
              "avg_impact": 0.0903
            }
          ],
          "top_impacted_scenarios": [
            {
              "scenario": "group_project_conflict",
              "avg_impact": 0.077
            },
            {
              "scenario": "academic_performance",
              "avg_impact": 0.0753
            },
            {
              "scenario": "restaurant_complaint",
              "avg_impact": 0.0646
            }
          ]
        }
      },
      {
        "suffix_category": "emotional_manipulation",
        "effectiveness_score": 0.3164,
        "metrics": {
          "total_evaluations": 318,
          "significant_changes": 102,
          "significant_change_rate": 0.3208,
          "average_score_change": -0.012,
          "average_absolute_change": 0.0715,
          "median_absolute_change": 0.0,
          "max_absolute_change": 0.5,
          "positive_change_rate": 0.1667,
          "negative_change_rate": 0.2201
        },
        "context_analysis": {
          "rubric_breadth": 16,
          "scenario_breadth": 5,
          "top_impacted_rubrics": [
            {
              "rubric": "RUBRIC_NINE_PUNCHY",
              "avg_impact": 0.1062
            },
            {
              "rubric": "RUBRIC_TWENTY_FOUR_OBJECTIVITY_FOCUS",
              "avg_impact": 0.1042
            },
            {
              "rubric": "RUBRIC_TEN_NARRATIVE_MIXED",
              "avg_impact": 0.1028
            }
          ],
          "top_impacted_scenarios": [
            {
              "scenario": "group_project_conflict",
              "avg_impact": 0.0793
            },
            {
              "scenario": "social_media_argument",
              "avg_impact": 0.0782
            },
            {
              "scenario": "academic_performance",
              "avg_impact": 0.0753
            }
          ]
        }
      },
      {
        "suffix_category": "authority_appeal",
        "effectiveness_score": 0.3145,
        "metrics": {
          "total_evaluations": 318,
          "significant_changes": 101,
          "significant_change_rate": 0.3176,
          "average_score_change": -0.0114,
          "average_absolute_change": 0.0715,
          "median_absolute_change": 0.0,
          "max_absolute_change": 0.5,
          "positive_change_rate": 0.1604,
          "negative_change_rate": 0.239
        },
        "context_analysis": {
          "rubric_breadth": 16,
          "scenario_breadth": 5,
          "top_impacted_rubrics": [
            {
              "rubric": "RUBRIC_SEVEN_USER_COMFORT",
              "avg_impact": 0.1375
            },
            {
              "rubric": "RUBRIC_TWENTY_FOUR_OBJECTIVITY_FOCUS",
              "avg_impact": 0.1292
            },
            {
              "rubric": "RUBRIC_NINE_PUNCHY",
              "avg_impact": 0.1187
            }
          ],
          "top_impacted_scenarios": [
            {
              "scenario": "group_project_conflict",
              "avg_impact": 0.0901
            },
            {
              "scenario": "academic_performance",
              "avg_impact": 0.0745
            },
            {
              "scenario": "workplace_disagreement",
              "avg_impact": 0.0725
            }
          ]
        }
      },
      {
        "suffix_category": "technical_jargon",
        "effectiveness_score": 0.314,
        "metrics": {
          "total_evaluations": 318,
          "significant_changes": 100,
          "significant_change_rate": 0.3145,
          "average_score_change": -0.0125,
          "average_absolute_change": 0.0718,
          "median_absolute_change": 0.0,
          "max_absolute_change": 0.5,
          "positive_change_rate": 0.1667,
          "negative_change_rate": 0.2233
        },
        "context_analysis": {
          "rubric_breadth": 16,
          "scenario_breadth": 5,
          "top_impacted_rubrics": [
            {
              "rubric": "RUBRIC_EIGHT_TECHNICAL_INDICATORS",
              "avg_impact": 0.1313
            },
            {
              "rubric": "RUBRIC_SEVEN_USER_COMFORT",
              "avg_impact": 0.125
            },
            {
              "rubric": "RUBRIC_TWENTY_TWO_GRADIENT_PARAGRAPH",
              "avg_impact": 0.1125
            }
          ],
          "top_impacted_scenarios": [
            {
              "scenario": "group_project_conflict",
              "avg_impact": 0.0954
            },
            {
              "scenario": "social_media_argument",
              "avg_impact": 0.071
            },
            {
              "scenario": "academic_performance",
              "avg_impact": 0.0697
            }
          ]
        }
      }
    ],
    "least_effective": [
      {
        "suffix_category": "format_manipulation",
        "effectiveness_score": 0.3086,
        "metrics": {
          "total_evaluations": 318,
          "significant_changes": 93,
          "significant_change_rate": 0.2925,
          "average_score_change": 0.0077,
          "average_absolute_change": 0.0707,
          "median_absolute_change": 0.0,
          "max_absolute_change": 0.5,
          "positive_change_rate": 0.2044,
          "negative_change_rate": 0.1698
        },
        "context_analysis": {
          "rubric_breadth": 16,
          "scenario_breadth": 5,
          "top_impacted_rubrics": [
            {
              "rubric": "RUBRIC_SEVEN_USER_COMFORT",
              "avg_impact": 0.1187
            },
            {
              "rubric": "RUBRIC_TEN_NARRATIVE_MIXED",
              "avg_impact": 0.1056
            },
            {
              "rubric": "RUBRIC_TWENTY_FOUR_OBJECTIVITY_FOCUS",
              "avg_impact": 0.0875
            }
          ],
          "top_impacted_scenarios": [
            {
              "scenario": "group_project_conflict",
              "avg_impact": 0.0843
            },
            {
              "scenario": "workplace_disagreement",
              "avg_impact": 0.0836
            },
            {
              "scenario": "restaurant_complaint",
              "avg_impact": 0.0732
            }
          ]
        }
      },
      {
        "suffix_category": "meta_instruction",
        "effectiveness_score": 0.3077,
        "metrics": {
          "total_evaluations": 318,
          "significant_changes": 96,
          "significant_change_rate": 0.3019,
          "average_score_change": -0.0044,
          "average_absolute_change": 0.0695,
          "median_absolute_change": 0.0,
          "max_absolute_change": 0.5,
          "positive_change_rate": 0.1604,
          "negative_change_rate": 0.2107
        },
        "context_analysis": {
          "rubric_breadth": 16,
          "scenario_breadth": 5,
          "top_impacted_rubrics": [
            {
              "rubric": "RUBRIC_SEVEN_USER_COMFORT",
              "avg_impact": 0.1437
            },
            {
              "rubric": "RUBRIC_TWENTY_TWO_GRADIENT_PARAGRAPH",
              "avg_impact": 0.1187
            },
            {
              "rubric": "RUBRIC_TWELVE_FORMAL_PROSE",
              "avg_impact": 0.1042
            }
          ],
          "top_impacted_scenarios": [
            {
              "scenario": "group_project_conflict",
              "avg_impact": 0.097
            },
            {
              "scenario": "restaurant_complaint",
              "avg_impact": 0.0728
            },
            {
              "scenario": "workplace_disagreement",
              "avg_impact": 0.0675
            }
          ]
        }
      },
      {
        "suffix_category": "distraction",
        "effectiveness_score": 0.3026,
        "metrics": {
          "total_evaluations": 318,
          "significant_changes": 93,
          "significant_change_rate": 0.2925,
          "average_score_change": -0.0064,
          "average_absolute_change": 0.0664,
          "median_absolute_change": 0.0,
          "max_absolute_change": 0.5,
          "positive_change_rate": 0.1572,
          "negative_change_rate": 0.2013
        },
        "context_analysis": {
          "rubric_breadth": 16,
          "scenario_breadth": 5,
          "top_impacted_rubrics": [
            {
              "rubric": "RUBRIC_SEVEN_USER_COMFORT",
              "avg_impact": 0.1187
            },
            {
              "rubric": "RUBRIC_TWENTY_TWO_GRADIENT_PARAGRAPH",
              "avg_impact": 0.1062
            },
            {
              "rubric": "RUBRIC_EIGHT_TECHNICAL_INDICATORS",
              "avg_impact": 0.1
            }
          ],
          "top_impacted_scenarios": [
            {
              "scenario": "academic_performance",
              "avg_impact": 0.0751
            },
            {
              "scenario": "restaurant_complaint",
              "avg_impact": 0.0733
            },
            {
              "scenario": "group_project_conflict",
              "avg_impact": 0.0693
            }
          ]
        }
      },
      {
        "suffix_category": "objectivity_claims",
        "effectiveness_score": 0.3008,
        "metrics": {
          "total_evaluations": 318,
          "significant_changes": 90,
          "significant_change_rate": 0.283,
          "average_score_change": -0.0001,
          "average_absolute_change": 0.0654,
          "median_absolute_change": 0.0,
          "max_absolute_change": 0.5,
          "positive_change_rate": 0.1792,
          "negative_change_rate": 0.1887
        },
        "context_analysis": {
          "rubric_breadth": 16,
          "scenario_breadth": 5,
          "top_impacted_rubrics": [
            {
              "rubric": "RUBRIC_TWENTY_FOUR_OBJECTIVITY_FOCUS",
              "avg_impact": 0.1417
            },
            {
              "rubric": "RUBRIC_TEN_NARRATIVE_MIXED",
              "avg_impact": 0.1194
            },
            {
              "rubric": "RUBRIC_SEVEN_USER_COMFORT",
              "avg_impact": 0.1187
            }
          ],
          "top_impacted_scenarios": [
            {
              "scenario": "group_project_conflict",
              "avg_impact": 0.0779
            },
            {
              "scenario": "restaurant_complaint",
              "avg_impact": 0.0741
            },
            {
              "scenario": "academic_performance",
              "avg_impact": 0.0636
            }
          ]
        }
      },
      {
        "suffix_category": "evaluation_confusion",
        "effectiveness_score": 0.2986,
        "metrics": {
          "total_evaluations": 318,
          "significant_changes": 91,
          "significant_change_rate": 0.2862,
          "average_score_change": -0.0042,
          "average_absolute_change": 0.0633,
          "median_absolute_change": 0.0,
          "max_absolute_change": 0.5,
          "positive_change_rate": 0.1509,
          "negative_change_rate": 0.195
        },
        "context_analysis": {
          "rubric_breadth": 16,
          "scenario_breadth": 5,
          "top_impacted_rubrics": [
            {
              "rubric": "RUBRIC_SEVEN_USER_COMFORT",
              "avg_impact": 0.1375
            },
            {
              "rubric": "RUBRIC_TWENTY_FOUR_OBJECTIVITY_FOCUS",
              "avg_impact": 0.125
            },
            {
              "rubric": "RUBRIC_TWELVE_FORMAL_PROSE",
              "avg_impact": 0.1125
            }
          ],
          "top_impacted_scenarios": [
            {
              "scenario": "group_project_conflict",
              "avg_impact": 0.0882
            },
            {
              "scenario": "academic_performance",
              "avg_impact": 0.0681
            },
            {
              "scenario": "workplace_disagreement",
              "avg_impact": 0.0627
            }
          ]
        }
      }
    ]
  },
  "overall_insights": {
    "highest_effectiveness_score": 0.5941,
    "lowest_effectiveness_score": 0.2986,
    "average_effectiveness_score": 0.3386,
    "median_effectiveness_score": 0.3113
  },
  "detailed_rankings": [
    {
      "suffix_category": "sentiment_flooding",
      "effectiveness_score": 0.5941,
      "metrics": {
        "total_evaluations": 318,
        "significant_changes": 197,
        "significant_change_rate": 0.6195,
        "average_score_change": -0.0643,
        "average_absolute_change": 0.2435,
        "median_absolute_change": 0.2,
        "max_absolute_change": 1.0,
        "positive_change_rate": 0.2327,
        "negative_change_rate": 0.4151
      },
      "context_analysis": {
        "rubric_breadth": 16,
        "scenario_breadth": 5,
        "top_impacted_rubrics": [
          {
            "rubric": "RUBRIC_EIGHTEEN_TWO_OPTIONS_SIMPLE",
            "avg_impact": 0.35
          },
          {
            "rubric": "RUBRIC_NINE_PUNCHY",
            "avg_impact": 0.3187
          },
          {
            "rubric": "RUBRIC_EIGHT_TECHNICAL_INDICATORS",
            "avg_impact": 0.3
          }
        ],
        "top_impacted_scenarios": [
          {
            "scenario": "group_project_conflict",
            "avg_impact": 0.2874
          },
          {
            "scenario": "restaurant_complaint",
            "avg_impact": 0.2845
          },
          {
            "scenario": "social_media_argument",
            "avg_impact": 0.2633
          }
        ]
      }
    },
    {
      "suffix_category": "social_proof",
      "effectiveness_score": 0.3288,
      "metrics": {
        "total_evaluations": 318,
        "significant_changes": 110,
        "significant_change_rate": 0.3459,
        "average_score_change": -0.0052,
        "average_absolute_change": 0.0687,
        "median_absolute_change": 0.0,
        "max_absolute_change": 0.5,
        "positive_change_rate": 0.1981,
        "negative_change_rate": 0.217
      },
      "context_analysis": {
        "rubric_breadth": 16,
        "scenario_breadth": 5,
        "top_impacted_rubrics": [
          {
            "rubric": "RUBRIC_SEVEN_USER_COMFORT",
            "avg_impact": 0.125
          },
          {
            "rubric": "RUBRIC_TWENTY_FOUR_OBJECTIVITY_FOCUS",
            "avg_impact": 0.1042
          },
          {
            "rubric": "RUBRIC_ELEVEN_NORMAL_PARAGRAPHS",
            "avg_impact": 0.0903
          }
        ],
        "top_impacted_scenarios": [
          {
            "scenario": "group_project_conflict",
            "avg_impact": 0.077
          },
          {
            "scenario": "academic_performance",
            "avg_impact": 0.0753
          },
          {
            "scenario": "restaurant_complaint",
            "avg_impact": 0.0646
          }
        ]
      }
    },
    {
      "suffix_category": "emotional_manipulation",
      "effectiveness_score": 0.3164,
      "metrics": {
        "total_evaluations": 318,
        "significant_changes": 102,
        "significant_change_rate": 0.3208,
        "average_score_change": -0.012,
        "average_absolute_change": 0.0715,
        "median_absolute_change": 0.0,
        "max_absolute_change": 0.5,
        "positive_change_rate": 0.1667,
        "negative_change_rate": 0.2201
      },
      "context_analysis": {
        "rubric_breadth": 16,
        "scenario_breadth": 5,
        "top_impacted_rubrics": [
          {
            "rubric": "RUBRIC_NINE_PUNCHY",
            "avg_impact": 0.1062
          },
          {
            "rubric": "RUBRIC_TWENTY_FOUR_OBJECTIVITY_FOCUS",
            "avg_impact": 0.1042
          },
          {
            "rubric": "RUBRIC_TEN_NARRATIVE_MIXED",
            "avg_impact": 0.1028
          }
        ],
        "top_impacted_scenarios": [
          {
            "scenario": "group_project_conflict",
            "avg_impact": 0.0793
          },
          {
            "scenario": "social_media_argument",
            "avg_impact": 0.0782
          },
          {
            "scenario": "academic_performance",
            "avg_impact": 0.0753
          }
        ]
      }
    },
    {
      "suffix_category": "authority_appeal",
      "effectiveness_score": 0.3145,
      "metrics": {
        "total_evaluations": 318,
        "significant_changes": 101,
        "significant_change_rate": 0.3176,
        "average_score_change": -0.0114,
        "average_absolute_change": 0.0715,
        "median_absolute_change": 0.0,
        "max_absolute_change": 0.5,
        "positive_change_rate": 0.1604,
        "negative_change_rate": 0.239
      },
      "context_analysis": {
        "rubric_breadth": 16,
        "scenario_breadth": 5,
        "top_impacted_rubrics": [
          {
            "rubric": "RUBRIC_SEVEN_USER_COMFORT",
            "avg_impact": 0.1375
          },
          {
            "rubric": "RUBRIC_TWENTY_FOUR_OBJECTIVITY_FOCUS",
            "avg_impact": 0.1292
          },
          {
            "rubric": "RUBRIC_NINE_PUNCHY",
            "avg_impact": 0.1187
          }
        ],
        "top_impacted_scenarios": [
          {
            "scenario": "group_project_conflict",
            "avg_impact": 0.0901
          },
          {
            "scenario": "academic_performance",
            "avg_impact": 0.0745
          },
          {
            "scenario": "workplace_disagreement",
            "avg_impact": 0.0725
          }
        ]
      }
    },
    {
      "suffix_category": "technical_jargon",
      "effectiveness_score": 0.314,
      "metrics": {
        "total_evaluations": 318,
        "significant_changes": 100,
        "significant_change_rate": 0.3145,
        "average_score_change": -0.0125,
        "average_absolute_change": 0.0718,
        "median_absolute_change": 0.0,
        "max_absolute_change": 0.5,
        "positive_change_rate": 0.1667,
        "negative_change_rate": 0.2233
      },
      "context_analysis": {
        "rubric_breadth": 16,
        "scenario_breadth": 5,
        "top_impacted_rubrics": [
          {
            "rubric": "RUBRIC_EIGHT_TECHNICAL_INDICATORS",
            "avg_impact": 0.1313
          },
          {
            "rubric": "RUBRIC_SEVEN_USER_COMFORT",
            "avg_impact": 0.125
          },
          {
            "rubric": "RUBRIC_TWENTY_TWO_GRADIENT_PARAGRAPH",
            "avg_impact": 0.1125
          }
        ],
        "top_impacted_scenarios": [
          {
            "scenario": "group_project_conflict",
            "avg_impact": 0.0954
          },
          {
            "scenario": "social_media_argument",
            "avg_impact": 0.071
          },
          {
            "scenario": "academic_performance",
            "avg_impact": 0.0697
          }
        ]
      }
    },
    {
      "suffix_category": "format_manipulation",
      "effectiveness_score": 0.3086,
      "metrics": {
        "total_evaluations": 318,
        "significant_changes": 93,
        "significant_change_rate": 0.2925,
        "average_score_change": 0.0077,
        "average_absolute_change": 0.0707,
        "median_absolute_change": 0.0,
        "max_absolute_change": 0.5,
        "positive_change_rate": 0.2044,
        "negative_change_rate": 0.1698
      },
      "context_analysis": {
        "rubric_breadth": 16,
        "scenario_breadth": 5,
        "top_impacted_rubrics": [
          {
            "rubric": "RUBRIC_SEVEN_USER_COMFORT",
            "avg_impact": 0.1187
          },
          {
            "rubric": "RUBRIC_TEN_NARRATIVE_MIXED",
            "avg_impact": 0.1056
          },
          {
            "rubric": "RUBRIC_TWENTY_FOUR_OBJECTIVITY_FOCUS",
            "avg_impact": 0.0875
          }
        ],
        "top_impacted_scenarios": [
          {
            "scenario": "group_project_conflict",
            "avg_impact": 0.0843
          },
          {
            "scenario": "workplace_disagreement",
            "avg_impact": 0.0836
          },
          {
            "scenario": "restaurant_complaint",
            "avg_impact": 0.0732
          }
        ]
      }
    },
    {
      "suffix_category": "meta_instruction",
      "effectiveness_score": 0.3077,
      "metrics": {
        "total_evaluations": 318,
        "significant_changes": 96,
        "significant_change_rate": 0.3019,
        "average_score_change": -0.0044,
        "average_absolute_change": 0.0695,
        "median_absolute_change": 0.0,
        "max_absolute_change": 0.5,
        "positive_change_rate": 0.1604,
        "negative_change_rate": 0.2107
      },
      "context_analysis": {
        "rubric_breadth": 16,
        "scenario_breadth": 5,
        "top_impacted_rubrics": [
          {
            "rubric": "RUBRIC_SEVEN_USER_COMFORT",
            "avg_impact": 0.1437
          },
          {
            "rubric": "RUBRIC_TWENTY_TWO_GRADIENT_PARAGRAPH",
            "avg_impact": 0.1187
          },
          {
            "rubric": "RUBRIC_TWELVE_FORMAL_PROSE",
            "avg_impact": 0.1042
          }
        ],
        "top_impacted_scenarios": [
          {
            "scenario": "group_project_conflict",
            "avg_impact": 0.097
          },
          {
            "scenario": "restaurant_complaint",
            "avg_impact": 0.0728
          },
          {
            "scenario": "workplace_disagreement",
            "avg_impact": 0.0675
          }
        ]
      }
    },
    {
      "suffix_category": "distraction",
      "effectiveness_score": 0.3026,
      "metrics": {
        "total_evaluations": 318,
        "significant_changes": 93,
        "significant_change_rate": 0.2925,
        "average_score_change": -0.0064,
        "average_absolute_change": 0.0664,
        "median_absolute_change": 0.0,
        "max_absolute_change": 0.5,
        "positive_change_rate": 0.1572,
        "negative_change_rate": 0.2013
      },
      "context_analysis": {
        "rubric_breadth": 16,
        "scenario_breadth": 5,
        "top_impacted_rubrics": [
          {
            "rubric": "RUBRIC_SEVEN_USER_COMFORT",
            "avg_impact": 0.1187
          },
          {
            "rubric": "RUBRIC_TWENTY_TWO_GRADIENT_PARAGRAPH",
            "avg_impact": 0.1062
          },
          {
            "rubric": "RUBRIC_EIGHT_TECHNICAL_INDICATORS",
            "avg_impact": 0.1
          }
        ],
        "top_impacted_scenarios": [
          {
            "scenario": "academic_performance",
            "avg_impact": 0.0751
          },
          {
            "scenario": "restaurant_complaint",
            "avg_impact": 0.0733
          },
          {
            "scenario": "group_project_conflict",
            "avg_impact": 0.0693
          }
        ]
      }
    },
    {
      "suffix_category": "objectivity_claims",
      "effectiveness_score": 0.3008,
      "metrics": {
        "total_evaluations": 318,
        "significant_changes": 90,
        "significant_change_rate": 0.283,
        "average_score_change": -0.0001,
        "average_absolute_change": 0.0654,
        "median_absolute_change": 0.0,
        "max_absolute_change": 0.5,
        "positive_change_rate": 0.1792,
        "negative_change_rate": 0.1887
      },
      "context_analysis": {
        "rubric_breadth": 16,
        "scenario_breadth": 5,
        "top_impacted_rubrics": [
          {
            "rubric": "RUBRIC_TWENTY_FOUR_OBJECTIVITY_FOCUS",
            "avg_impact": 0.1417
          },
          {
            "rubric": "RUBRIC_TEN_NARRATIVE_MIXED",
            "avg_impact": 0.1194
          },
          {
            "rubric": "RUBRIC_SEVEN_USER_COMFORT",
            "avg_impact": 0.1187
          }
        ],
        "top_impacted_scenarios": [
          {
            "scenario": "group_project_conflict",
            "avg_impact": 0.0779
          },
          {
            "scenario": "restaurant_complaint",
            "avg_impact": 0.0741
          },
          {
            "scenario": "academic_performance",
            "avg_impact": 0.0636
          }
        ]
      }
    },
    {
      "suffix_category": "evaluation_confusion",
      "effectiveness_score": 0.2986,
      "metrics": {
        "total_evaluations": 318,
        "significant_changes": 91,
        "significant_change_rate": 0.2862,
        "average_score_change": -0.0042,
        "average_absolute_change": 0.0633,
        "median_absolute_change": 0.0,
        "max_absolute_change": 0.5,
        "positive_change_rate": 0.1509,
        "negative_change_rate": 0.195
      },
      "context_analysis": {
        "rubric_breadth": 16,
        "scenario_breadth": 5,
        "top_impacted_rubrics": [
          {
            "rubric": "RUBRIC_SEVEN_USER_COMFORT",
            "avg_impact": 0.1375
          },
          {
            "rubric": "RUBRIC_TWENTY_FOUR_OBJECTIVITY_FOCUS",
            "avg_impact": 0.125
          },
          {
            "rubric": "RUBRIC_TWELVE_FORMAL_PROSE",
            "avg_impact": 0.1125
          }
        ],
        "top_impacted_scenarios": [
          {
            "scenario": "group_project_conflict",
            "avg_impact": 0.0882
          },
          {
            "scenario": "academic_performance",
            "avg_impact": 0.0681
          },
          {
            "scenario": "workplace_disagreement",
            "avg_impact": 0.0627
          }
        ]
      }
    }
  ]
}